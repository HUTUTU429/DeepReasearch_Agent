"""
å¤š Agent åä½œæ¶æ„
å®ç°ï¼šä»»åŠ¡æ‹†è§£ Agentã€ä¿¡æ¯æ”¶é›† Agentã€æŠ¥å‘Šç”Ÿæˆ Agent
"""
from typing import AsyncIterator, Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage, AIMessage
from config import get_llm_config
from tools.tavily_search import get_search_tools
import json

# ä»»åŠ¡è§„åˆ’ Agent æç¤ºè¯
PLANNER_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶ä»»åŠ¡è§„åˆ’ä¸“å®¶ã€‚

ä½ çš„èŒè´£æ˜¯ï¼š
1. åˆ†æç”¨æˆ·çš„ç ”ç©¶éœ€æ±‚
2. å°†ç ”ç©¶ä»»åŠ¡æ‹†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡
3. ä¸ºæ¯ä¸ªå­ä»»åŠ¡åˆ¶å®šå…·ä½“çš„è°ƒç ”æ–¹å‘

ç”¨æˆ·é—®é¢˜ï¼š{input}

è¯·å°†ä»»åŠ¡æ‹†è§£ä¸º 3-5 ä¸ªå…·ä½“çš„å­ä»»åŠ¡ï¼Œæ¯ä¸ªå­ä»»åŠ¡åº”è¯¥åŒ…æ‹¬ï¼š
- ä»»åŠ¡æ ‡é¢˜
- è°ƒç ”æ–¹å‘å’Œå…³é”®é—®é¢˜
- é¢„æœŸè¾“å‡º

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œä¾‹å¦‚ï¼š
```json
{{
  "research_plan": [
    {{
      "task_id": 1,
      "title": "ä»»åŠ¡æ ‡é¢˜",
      "directions": ["æ–¹å‘1", "æ–¹å‘2"],
      "expected_output": "é¢„æœŸè¾“å‡ºæè¿°"
    }}
  ]
}}
```
"""

# ä¿¡æ¯æ”¶é›† Agent æç¤ºè¯
RESEARCHER_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯æ”¶é›†ä¸“å®¶ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·è¿›è¡Œä¿¡æ¯æœç´¢ï¼š
{tools}

å·¥å…·åç§°: {tool_names}

ä½ çš„èŒè´£æ˜¯ï¼š
1. æ ¹æ®ç»™å®šçš„ç ”ç©¶ä»»åŠ¡ï¼Œä½¿ç”¨æœç´¢å·¥å…·æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯
2. å¯¹æœç´¢ç»“æœè¿›è¡Œåˆ†æå’Œç­›é€‰
3. æå–å…³é”®ä¿¡æ¯å’Œæ•°æ®
4. æ•´ç†æˆç»“æ„åŒ–çš„è¾“å‡º

è¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š

Question: ç ”ç©¶ä»»åŠ¡
Thought: ä½ åº”è¯¥æ€è€ƒè¦æœç´¢ä»€ä¹ˆ
Action: è¦ä½¿ç”¨çš„å·¥å…·ï¼Œåº”è¯¥æ˜¯ [{tool_names}] ä¸­çš„ä¸€ä¸ª
Action Input: å·¥å…·çš„è¾“å…¥å‚æ•°
Observation: å·¥å…·è¿”å›çš„ç»“æœ
... (å¯ä»¥é‡å¤å¤šæ¬¡æœç´¢)
Thought: æˆ‘å·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯
Final Answer: æ•´ç†åçš„ç ”ç©¶ç»“æœï¼ˆç»“æ„åŒ–è¾“å‡ºï¼‰

é‡è¦æç¤ºï¼š
- ä»å¤šä¸ªè§’åº¦æœç´¢ä¿¡æ¯ï¼Œç¡®ä¿å…¨é¢æ€§
- æ³¨æ„ä¿¡æ¯çš„æ¥æºå’Œå¯ä¿¡åº¦
- æå–å…³é”®æ•°æ®å’Œè§‚ç‚¹
- ç»“æœè¦ç»“æ„åŒ–ã€æ¡ç†æ¸…æ™°

ç ”ç©¶ä»»åŠ¡ï¼š{input}
Thought: {agent_scratchpad}
"""

# æŠ¥å‘Šç”Ÿæˆ Agent æç¤ºè¯
WRITER_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶æŠ¥å‘Šæ’°å†™ä¸“å®¶ã€‚

ä½ çš„èŒè´£æ˜¯ï¼š
1. ç»¼åˆæ‰€æœ‰å­ä»»åŠ¡çš„ç ”ç©¶ç»“æœ
2. åˆ†æå’Œæ•´åˆä¿¡æ¯
3. æ’°å†™ä¸€ä»½ç»“æ„æ¸…æ™°ã€å†…å®¹è¯¦å®çš„ç ”ç©¶æŠ¥å‘Š

æŠ¥å‘Šè¦æ±‚ï¼š
- ä½¿ç”¨ Markdown æ ¼å¼
- åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
  * æ‘˜è¦ï¼ˆExecutive Summaryï¼‰
  * èƒŒæ™¯ä»‹ç»ï¼ˆBackgroundï¼‰
  * è¯¦ç»†åˆ†æï¼ˆDetailed Analysisï¼‰- åŒ…å«å„ä¸ªå­ä¸»é¢˜
  * å…³é”®å‘ç°ï¼ˆKey Findingsï¼‰
  * ç»“è®ºå’Œå±•æœ›ï¼ˆConclusion & Outlookï¼‰
- å†…å®¹è¦æœ‰ç†æœ‰æ®ï¼Œå¼•ç”¨å…·ä½“ä¿¡æ¯
- è¯­è¨€ä¸“ä¸šã€å®¢è§‚

ç ”ç©¶ä¸»é¢˜ï¼š{topic}

å­ä»»åŠ¡ç ”ç©¶ç»“æœï¼š
{research_results}

è¯·æ’°å†™å®Œæ•´çš„ç ”ç©¶æŠ¥å‘Šï¼š
"""

class MultiAgentResearcher:
    """å¤š Agent ç ”ç©¶ç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¤šä¸ª Agent"""
        llm_config = get_llm_config()
        
        # åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            model=llm_config["model"],
            temperature=llm_config["temperature"],
            api_key=llm_config["api_key"],
            base_url=llm_config["api_base"],
            streaming=True,
        )
        
        # ä½æ¸©åº¦ LLMï¼ˆç”¨äºè§„åˆ’å’Œå†™ä½œï¼‰
        self.llm_low_temp = ChatOpenAI(
            model=llm_config["model"],
            temperature=0.3,
            api_key=llm_config["api_key"],
            base_url=llm_config["api_base"],
        )
        
        # è·å–å·¥å…·
        self.tools = get_search_tools()
        
        # åˆå§‹åŒ–å„ä¸ª Agent
        self._init_agents()
    
    def _init_agents(self):
        """åˆå§‹åŒ–å„ä¸ªå­ Agent"""
        
        # ç ”ç©¶å‘˜ Agentï¼ˆå¸¦å·¥å…·ï¼‰
        researcher_prompt = PromptTemplate.from_template(RESEARCHER_PROMPT)
        researcher_agent = create_react_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=researcher_prompt
        )
        self.researcher_executor = AgentExecutor(
            agent=researcher_agent,
            tools=self.tools,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=8,
        )
    
    async def plan_research(self, query: str) -> List[Dict[str, Any]]:
        """
        è§„åˆ’ç ”ç©¶ä»»åŠ¡
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            List[Dict]: ç ”ç©¶ä»»åŠ¡åˆ—è¡¨
        """
        try:
            prompt = PLANNER_PROMPT.format(input=query)
            response = await self.llm_low_temp.ainvoke([HumanMessage(content=prompt)])
            
            # è§£æ JSON
            content = response.content
            
            # æå– JSON éƒ¨åˆ†
            if "```json" in content:
                json_start = content.find("```json") + 7
                json_end = content.find("```", json_start)
                json_str = content[json_start:json_end].strip()
            elif "```" in content:
                json_start = content.find("```") + 3
                json_end = content.find("```", json_start)
                json_str = content[json_start:json_end].strip()
            else:
                json_str = content
            
            plan_data = json.loads(json_str)
            return plan_data.get("research_plan", [])
            
        except Exception as e:
            print(f"Plan research error: {e}")
            # è¿”å›é»˜è®¤è®¡åˆ’
            return [
                {
                    "task_id": 1,
                    "title": "æ·±åº¦ç ”ç©¶ï¼š" + query,
                    "directions": ["å…¨é¢æœç´¢ç›¸å…³ä¿¡æ¯"],
                    "expected_output": "è¯¦ç»†ç ”ç©¶ç»“æœ"
                }
            ]
    
    async def research_task(self, task: Dict[str, Any]) -> str:
        """
        æ‰§è¡Œå•ä¸ªç ”ç©¶ä»»åŠ¡
        
        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            
        Returns:
            str: ç ”ç©¶ç»“æœ
        """
        try:
            # æ„å»ºç ”ç©¶æŸ¥è¯¢
            query = f"{task['title']}\n"
            query += f"è°ƒç ”æ–¹å‘ï¼š{', '.join(task['directions'])}\n"
            query += f"é¢„æœŸè¾“å‡ºï¼š{task['expected_output']}"
            
            # æ‰§è¡Œç ”ç©¶
            result = await self.researcher_executor.ainvoke({"input": query})
            return result.get("output", "")
            
        except Exception as e:
            print(f"Research task error: {e}")
            return f"ä»»åŠ¡æ‰§è¡Œå‡ºé”™ï¼š{str(e)}"
    
    async def generate_report(self, topic: str, research_results: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆç ”ç©¶æŠ¥å‘Š
        
        Args:
            topic: ç ”ç©¶ä¸»é¢˜
            research_results: å„å­ä»»åŠ¡çš„ç ”ç©¶ç»“æœ
            
        Returns:
            str: å®Œæ•´æŠ¥å‘Š
        """
        try:
            # æ•´ç†ç ”ç©¶ç»“æœ
            results_text = ""
            for i, result in enumerate(research_results, 1):
                results_text += f"\n## å­ä»»åŠ¡ {i}: {result['task']['title']}\n"
                results_text += f"{result['result']}\n"
            
            # ç”ŸæˆæŠ¥å‘Š
            prompt = WRITER_PROMPT.format(
                topic=topic,
                research_results=results_text
            )
            
            response = await self.llm_low_temp.ainvoke([HumanMessage(content=prompt)])
            return response.content
            
        except Exception as e:
            print(f"Generate report error: {e}")
            return f"æŠ¥å‘Šç”Ÿæˆå‡ºé”™ï¼š{str(e)}"
    
    async def astream(self, query: str) -> AsyncIterator[Dict[str, Any]]:
        """
        æµå¼æ‰§è¡Œå®Œæ•´çš„å¤š Agent ç ”ç©¶æµç¨‹
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            
        Yields:
            Dict[str, Any]: æµå¼äº‹ä»¶
        """
        try:
            # æ­¥éª¤ 1: è§„åˆ’ä»»åŠ¡
            yield {
                "type": "thinking",
                "content": "ğŸ¯ æ­£åœ¨è§„åˆ’ç ”ç©¶ä»»åŠ¡...",
                "metadata": {"step": "planning"}
            }
            
            tasks = await self.plan_research(query)
            
            yield {
                "type": "agent_action",
                "content": {
                    "action": "plan_created",
                    "tasks": tasks
                },
                "metadata": {"step": "planning", "task_count": len(tasks)}
            }
            
            # æ­¥éª¤ 2: æ‰§è¡Œå„ä¸ªå­ä»»åŠ¡
            research_results = []
            
            for i, task in enumerate(tasks, 1):
                yield {
                    "type": "thinking",
                    "content": f"ğŸ“š æ­£åœ¨æ‰§è¡Œå­ä»»åŠ¡ {i}/{len(tasks)}: {task['title']}",
                    "metadata": {"step": "researching", "task_id": task['task_id']}
                }
                
                # æ‰§è¡Œç ”ç©¶ä»»åŠ¡ï¼ˆæµå¼è¾“å‡ºå·¥å…·è°ƒç”¨ï¼‰
                result = await self.research_task(task)
                
                research_results.append({
                    "task": task,
                    "result": result
                })
                
                yield {
                    "type": "agent_action",
                    "content": {
                        "action": "task_completed",
                        "task_id": task['task_id'],
                        "title": task['title']
                    },
                    "metadata": {"step": "researching"}
                }
            
            # æ­¥éª¤ 3: ç”ŸæˆæŠ¥å‘Š
            yield {
                "type": "thinking",
                "content": "âœï¸ æ­£åœ¨æ’°å†™ç ”ç©¶æŠ¥å‘Š...",
                "metadata": {"step": "writing"}
            }
            
            report = await self.generate_report(query, research_results)
            
            # è¾“å‡ºæŠ¥å‘Šï¼ˆé€æ®µæµå¼è¾“å‡ºï¼‰
            paragraphs = report.split('\n\n')
            for paragraph in paragraphs:
                if paragraph.strip():
                    yield {
                        "type": "text",
                        "content": paragraph + "\n\n",
                        "metadata": {"step": "output"}
                    }
            
            # å®Œæˆ
            yield {
                "type": "done",
                "content": "completed",
                "metadata": {}
            }
            
        except Exception as e:
            yield {
                "type": "error",
                "content": str(e),
                "metadata": {}
            }

